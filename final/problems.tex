\section{Problems and Algorithms}\label{sec:problems}

The chromatic number problem is \emph{inherently intractable}.  Informally, this means that finding a solution for
a given input graph, regardless of the means, can take a very, very long time in the worst cases.  Thus, trying to
find an efficient \emph{and} exact method of solution that satisfies all cases is a fool's errand; about the best
that can be done is to perform better than other well-known methods in most cases.

Computation theory is the branch of computer science that is concerned with determining and comparing the runtime
performance of algorithms.  The history and specifics of computation theory, although interesting, are beyond the
scope of this research.  Instead, this section presents a brief overview of what is needed from the field of
computation theory in order to characterize the chromatic number problem.  Most of this material is based on the
early yet still very influential text by Garey and Johnson (1979)~\cite{garey} with some help from Spiser
(2013)~\cite{sipser}.  The material on incremental algorithm development is highly influenced by
Johnston~(1976)~\cite{johnston}.

\subsection{Problems}\label{sec:sub:problems}

A \emph{problem} consists of three parts:

\begin{enumerate}
\item A specific question to be answered.
\item A description of zero or more input \emph{parameters}.
\item A statement of the properties that the \emph{solution} is required to satisfy.
\end{enumerate}

An \emph{instance} of a problem is constructed by specifying particular values for each input parameter.  The
step-by-step procedure that translates the input parameters to a corresponding well-defined solution is called an
\emph{algorithm}.  To say that an algorithm \emph{solves} a problem means that the algorithm produces a valid
solution for every possible instance of the problem.

The chromatic number problem accepts a graph \(G\) and uses an algorithm to obtain a number \(k\in\N\) where \(k\)
is the minimum value such that \(G\) is \colorable{k}.  The proposed algorithm is one such algorithm that can be
used to solve the chromatic number problem.  Other examples are the Christofides (1971)~\cite{christofides} and the
Corneil/Graham (1973)~\cite{corneil} algorithms, which are introduced in the next section and will be compared to
the proposed algorithm using random graph analysis.

\subsection{Comparing Algorithms}\label{sec:sub:compare}

Algorithms are compared using three parameters:
\begin{enumerate}
\item Runtime complexity
\item Space complexity
\item Runtime duration
\end{enumerate}

These parameters are discussed in the following sections.

\subsubsection{Runtime Complexity}\label{sec:sub:sub:runtime}

\emph{Runtime complexity} measures the number of \emph{steps} required to obtain a solution for the worst possible
input parameter and is a function of some \emph{length} parameter of the problem.  For graph algorithms, the length
parameter is usually the order of the graph, although size and structure can also contribute to the worst case.

The runtime complexity of an algorithm is stated using the so-called \emph{big-\(\BO\)} notation: to say that an
algorithm has \(\BO(f(n))\) runtime complexity means that the maximum number of steps required to obtain a solution
for a given length parameter \(n\) is asymptotic to the function \(f(n)\) as \(n\to\infty\).  Roughly speaking,
tractable problems are those problems with polynomial \(\BO(n^c)\) or better runtime complexity for some real
number constant \(c\ge0\), and intractable problems are those problems with exponential \(\BO(c^n)\) or worse
runtime complexity for some real number constant \(c>1\).

What constitutes a \emph{step} in an algorithm is relative to the overall runtime complexity of the algorithm: any
process that has significantly less runtime complexity than the runtime complexity of the whole algorithm can be
called a step.  Thus, a process that has polynomial runtime complexity can be called a step of an algorithm that
has exponential runtime complexity.

Runtime complexity is used in two different ways to compare algorithms:
\begin{enumerate}
\item \emph{Finding} a solution to a problem given a particular input parameter.
\item \emph{Verifying} that a given solution is in fact a solution for a given input parameter.
\end{enumerate}

These two comparisons can be very different.  For example, finding a \clique{k} in a graph \(G\) for a particular
value of \(k\) has exponential runtime complexity; however, verifying whether or not a given subgraph of a graph is
a \(k\)-clique has polynomial runtime complexity.  Because of these differences, algorithms are categorized into
the computation classes shown in \tablename~\ref{tab:classes}.

\begin{table}[H]
  \centering
  \caption{Runtime Complexity Classes for Algorithms}
  \label{tab:classes}
  \setlength{\extrarowheight}{2ex}
  \begin{tabular}{|m{1in}|m{3in}|}
    \hline
    P & Algorithms with polynomial or better runtime complexity to find or verify a solution. \\
    \hline
    NP & A superset of P with varying runtime complexity to find a solution but polynomial runtime complexity to
    verify a solution. \\
    \hline
    NP-complete & A subset of NP problems that have been proven to have the same runtime complexity to find a
    solution.  It is an open question as to whether P=NP; however, it is conjectured that they are not equal. \\
    \hline
    NP-hard & Algorithms that have been proved to have the same runtime complexity as the NP-complete problems to
    find a solution but varying runtime complexity to verify a solution. \\
    \hline
  \end{tabular}
\end{table}

The relationships between these runtime complexity classes, assuming \(P\ne NP\), is shown in
\figurename~\ref{fig:complexity}.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \node at (0,0) [circle,draw,minimum size=2in] {NP};
    \node at (0,-1.5) [ellipse,draw,minimum width=1in, minimum height=0.5in] {P};
    \draw (0,1) parabola (3,4);
    \draw (0,1) parabola (-3,4);
    \node at (0,1.75) {NP-complete};
    \node at (0,3.25) {NP-hard};
  \end{tikzpicture}
  \caption{The runtime complexity classes.}
  \label{fig:complexity}
\end{figure}

For the purposes of this research, the NP-complete problems are assumed to have exponential runtime complexity to
find a solution and polynomial runtime complexity to verify a solution, and the NP-hard problems are assumed to
have exponential runtime for both finding and verifying solutions.

The chromatic number problem is NP-hard: it requires exponential time to exhaustively generate and check all
possible independent set partitions to find a partition with the smallest number of independent sets \(k\), and the
same basic procedure must be used to verify that given a supposed \(k\)-chromatic coloring, there does not exist a
proper coloring for smaller \(k\).

\subsubsection{Space Complexity}\label{sec:sub:sub:space}

\emph{Space complexity} measures the maximum amount of memory required at any point in time when an algorithm is
run on a computer.  The limited memory and CPU power in early computers forced algorithm designers and programmers
to make careful tradeoffs between CPU cycles and the storage of intermediate results.  With today's fast CPUs and
practically unlimited virtual memory systems, such concerns are not as important.  Thus, space complexity will not
be considered when comparing the selected well-known algorithms to the proposed algorithm.

\subsubsection{Runtime Duration}\label{sec:sub:sub:duration}

\emph{Runtime duration} is an empirical measurement of how long an algorithm runs on a given computer, usually on
best, average, and worst-case input parameter values.  Determining the runtime complexity for some algorithms can
be very complicated when the number of possible steps is dependent on the peculiarities of the input parameters.
In the case of graph algorithms, such things as order, size, and edge density can all affect the number of steps.
Furthermore, runtime complexity is geared towards theoretical comparisons between algorithms, not actual runtime of
an algorithm implementation on a given computer.  Thus, an important part of this research is a random graph
analysis of several well-known algorithms and the proposed algorithm.

\subsection{Branch and Bound Algorithms}

Exponential problems are usually associated with so-called \emph{brute-force} algorithms that must examine all
possibilities from an exponentially increasing set of candidate solutions in order to find the desired solution.
The states of a brute-force algorithm can be organized into a tree like that shown in \figurename~\ref{fig:tree}.
Each leaf node of the tree represents a candidate solution.  Each non-leaf node represents a partial solution and
serves as the root node of a subtree leading to a set of related candidate solutions.



Exponential algorithms can walk their state trees in either depth-first or breadth-first fashion.  This is
demonstrated in \figurename~\ref{fig:treewalks}

\begin{figure}[H]
  \begin{minipage}{3in}
    \centering
    \begin{tikzpicture}[every node/.style={labeled node}]
      \node (a) at (0,0) {\(a\)};
      \node (b) at (-2,-2) {\(b\)};
      \node (c) at (2,-2) {\(c\)};
      \node (d) at (-3,-4) {\(d\)};
      \node (e) at (-1,-4) {\(e\)};
      \node (f) at (1,-4) {\(f\)};
      \node (g) at (3,-4) {\(g\)};
      \draw (a) edge (b) edge (c);
      \draw (b) edge (d) edge (e);
      \draw (c) edge (f) edge (g);
    \end{tikzpicture}
    \caption{Depth-first versus breadth-first walks.}
    \label{fig:treewalks}
  \end{minipage}
  \begin{minipage}{2.5in}
    Depth: \((a,b,d,b,e,b,a,c,f,c,g,c,a)\)

    Breadth: \((a,b,c,d,e,f,g)\)
  \end{minipage}
\end{figure}

Although breadth-first walks are shorter, since nodes do not need to be revisited during the walk, they require
more storage since each level must be retained in full; depth-first walks only require that the current branch be
retained.

The goal when designing such tree-tracked brute-force algorithms is to find ways to \emph{prune} subtrees from the
tree: the less branches that need to be walked, the faster the algorithm.

