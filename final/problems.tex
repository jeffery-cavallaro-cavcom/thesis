\section{Problems and Algorithms}\label{sec:problems}

The chromatic number problem is \emph{inherently intractable}.  Informally, this means that finding a solution for
a given input graph, regardless of the means, can take a very, very long time in the worst cases.  Thus, trying to
find an efficient \emph{and} exact method of solution that satisfies all cases is a fool's errand; about the best
that can be done is to perform better than other well-known methods in most cases.

Computation theory is the branch of computer science that is concerned with determining and comparing the runtime
performance of algorithms.  The history and specifics of computation theory, although interesting, are beyond the
scope of this research.  Instead, this section presents a brief overview of what is needed from the field of
computation theory in order to characterize the chromatic number problem.  Most of this material is based on the
early yet still very influential text by Garey and Johnson (1979)~\cite{garey} with some help from Spiser
(2013)~\cite{sipser}.  The material on incremental algorithm development is highly influenced by
Johnston~(1976)~\cite{johnston}.

\subsection{Problems}\label{sec:sub:problems}

A \emph{problem} consists of three parts:

\begin{enumerate}
\item A specific question to be answered.
\item A description of zero or more input \emph{parameters}.
\item A statement of the properties that the \emph{solution} is required to satisfy.
\end{enumerate}

An \emph{instance} of a problem is constructed by specifying particular values for each input parameter.  The
step-by-step procedure that translates the input parameters to a corresponding well-defined solution is called an
\emph{algorithm}.  To say that an algorithm \emph{solves} a problem means that the algorithm produces a valid
solution for every possible instance of the problem.

The chromatic number problem accepts a graph \(G\) and uses an algorithm to obtain a number \(k\in\N\) where \(k\)
is the minimum value such that \(G\) is \colorable{k}.  The proposed algorithm is one such algorithm that can be
used to solve the chromatic number problem.  Other examples are the Christofides (1971)~\cite{christofides} and the
Corneil/Graham (1973)~\cite{corneil} algorithms, which are introduced in the next section and will be compared to
the proposed algorithm using random graph analysis.

\subsection{Comparing Algorithms}\label{sec:sub:compare}

Algorithms are compared using three parameters:
\begin{enumerate}
\item Runtime complexity
\item Space complexity
\item Runtime duration
\end{enumerate}

These parameters are discussed in the following sections.

\subsubsection{Runtime Complexity}\label{sec:sub:sub:runtime}

\emph{Runtime complexity} measures the number of \emph{steps} required to obtain a solution for the worst possible
input parameter and is a function of some \emph{length} parameter of the problem.  For graph algorithms, the length
parameter is usually the order of the graph, although size and structure can also contribute to the worst case.

The runtime complexity of an algorithm is stated using the so-called \emph{big-\(\BO\)} notation: to say that an
algorithm has \(\BO(f(n))\) runtime complexity means that the maximum number of steps required to obtain a solution
for a given length parameter \(n\) is asymptotic to the function \(f(n)\) as \(n\to\infty\).  Roughly speaking,
tractable problems are those problems with polynomial \(\BO(n^c)\) or better runtime complexity for some real
number constant \(c\ge0\), and intractable problems are those problems with exponential \(\BO(c^n)\) or worse
runtime complexity for some real number constant \(c>1\).

What constitutes a \emph{step} in an algorithm is relative to the overall runtime complexity of the algorithm: any
process that has significantly less runtime complexity than the runtime complexity of the whole algorithm can be
called a step.  Thus, a process that has polynomial runtime complexity can be called a step of an algorithm that
has exponential runtime complexity.

Runtime complexity is used in two different ways to compare algorithms:
\begin{enumerate}
\item \emph{Finding} a solution to a problem given a particular input parameter.
\item \emph{Verifying} that a given solution is in fact a solution for a given input parameter.
\end{enumerate}

These two comparisons can be very different.  For example, finding a \clique{k} in a graph \(G\) for a particular
value of \(k\) has exponential runtime complexity; however, verifying whether or not a given subgraph of a graph is
a \(k\)-clique has polynomial runtime complexity.  Because of these differences, algorithms are categorized into
the computation classes shown in \tablename~\ref{tab:classes}.

\begin{table}[H]
  \centering
  \caption{Runtime Complexity Classes for Algorithms}
  \label{tab:classes}
  \setlength{\extrarowheight}{2ex}
  \begin{tabular}{|m{1in}|m{3in}|}
    \hline
    P & Algorithms with polynomial or better runtime complexity to find or verify a solution. \\
    \hline
    NP & A superset of P with varying runtime complexity to find a solution but polynomial runtime complexity to
    verify a solution. \\
    \hline
    NP-complete & A subset of NP problems that have been proven to have the same runtime complexity to find a
    solution.  It is an open question as to whether P=NP; however, it is conjectured that they are not equal. \\
    \hline
    NP-hard & Algorithms that have been proved to have the same runtime complexity as the NP-complete problems to
    find a solution but varying runtime complexity to verify a solution. \\
    \hline
  \end{tabular}
\end{table}

The relationships between these runtime complexity classes, assuming \(P\ne NP\), is shown in
\figurename~\ref{fig:complexity}.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \node at (0,0) [circle,draw,minimum size=2in] {NP};
    \node at (0,-1.5) [ellipse,draw,minimum width=1in, minimum height=0.5in] {P};
    \draw (0,1) parabola (3,4);
    \draw (0,1) parabola (-3,4);
    \node at (0,1.75) {NP-complete};
    \node at (0,3.25) {NP-hard};
  \end{tikzpicture}
  \caption{The runtime complexity classes.}
  \label{fig:complexity}
\end{figure}

For the purposes of this research, the NP-complete problems are assumed to have exponential runtime complexity to
find a solution and polynomial runtime complexity to verify a solution, and the NP-hard problems are assumed to
have exponential runtime for both finding and verifying solutions.

The chromatic number problem is NP-hard: it requires exponential time to exhaustively generate and check all
possible independent set partitions to find a partition with the smallest number of independent sets \(k\), and the
same basic procedure must be used to verify that given a supposed \(k\)-chromatic coloring, there does not exist a
proper coloring for smaller \(k\).

\subsubsection{Space Complexity}\label{sec:sub:sub:space}

\emph{Space complexity} measures the maximum amount of memory required at any point in time when an algorithm is
run on a computer.  The limited memory and CPU power in early computers forced algorithm designers and programmers
to make careful tradeoffs between CPU cycles and the storage of intermediate results.  With today's fast CPUs and
practically unlimited virtual memory systems, such concerns are not as important.  Thus, space complexity will not
be considered when comparing the selected well-known algorithms to the proposed algorithm.

\subsubsection{Runtime Duration}\label{sec:sub:sub:duration}

\emph{Runtime duration} is an empirical measurement of how long an algorithm runs on a given computer, usually on
best, average, and worst-case input parameter values.  Determining the runtime complexity for some algorithms can
be very complicated when the number of possible steps is dependent on the peculiarities of the input parameters.
In the case of graph algorithms, such things as order, size, and edge density can all affect the number of steps.
Furthermore, runtime complexity is geared towards theoretical comparisons between algorithms, not actual runtime of
an algorithm implementation on a given computer.  Thus, an important part of this research is a random graph
analysis of several well-known algorithms and the proposed algorithm.

\subsection{Branch and Bound Algorithms}\label{sec:sub:bandb}

Exponential problems are usually associated with so-called \emph{brute-force} algorithms that must examine all
possibilities from an exponentially increasing set of candidate solutions in order to find the desired solution.
The states of a brute-force algorithm can be represented by nodes in a tree.  Each leaf node of the tree represents
a candidate solution.  Each non-leaf node represents a partial solution and serves as the root node of a subtree
leading to a set of related candidate solutions.  Such an algorithm is called a \emph{branching} algorithm because
each candidate solution can be found by walking a unique path through the tree starting at the root node and ending
at the candidate solution leaf node.

For example, consider the problem of finding all maximal cliques in the graph shown in
\figurename\ref{fig:maxexample}.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[every node/.style={labeled node},node distance=1in]
    \pathVnodes{\(1\),\(2\),\(3\)}{(0,0)}{right}{p};
    \draw (p1) edge (p2);
  \end{tikzpicture}
  \caption{Finding maximal cliques example graph.}
  \label{fig:maxexample}
\end{figure}

First, consider the rather na\"{\i}ve solution of examining every subgraph in the graph.  The resulting tree is
shown in \figurename\ref{fig:maxexall}.  Each node has two branches: include the next vertex and exclude the next
vertex.  The results are summarized in the last row: green marks the desired maximal cliques, blue marks
non-maximal cliques, and red marks non-cliques.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[every node/.style={labeled node}]
    \colorlet{c1}{green!25!white}
    \colorlet{c2}{blue!25!white}
    \colorlet{c3}{red!25!white}
    \node (1) at (0,0) {};
    \node (2) at (-4,-2) {\(1\)};
    \node (3) at (4,-2) {\(\bar{1}\)};
    \node (4) at (-6,-4) {\(12\)};
    \node (5) at (-2,-4) {\(1\bar{2}\)};
    \node (6) at (2,-4) {\(\bar{1}2\)};
    \node (7) at (6,-4) {\(\bar{1}\bar{2}\)};
    \node (8) at (-7,-6) {\(123\)};
    \node (9) at (-5,-6) {\(12\bar{3}\)};
    \node (10) at (-3,-6) {\(1\bar{2}3\)};
    \node (11) at (-1,-6) {\(1\bar{2}\bar{3}\)};
    \node (12) at (1,-6) {\(\bar{1}23\)};
    \node (13) at (3,-6) {\(\bar{1}2\bar{3}\)};
    \node (14) at (5,-6) {\(\bar{1}\bar{2}3\)};
    \node (15) at (7,-6) {\(\bar{1}\bar{2}\bar{3}\)};
    \node [fill=c3] (16) at (-7,-8) {\(123\)};
    \node [fill=c1] (17) at (-5,-8) {\(12\)};
    \node [fill=c3] (18) at (-3,-8) {\(13\)};
    \node [fill=c2] (19) at (-1,-8) {\(1\)};
    \node [fill=c3] (20) at (1,-8) {\(23\)};
    \node [fill=c2] (21) at (3,-8) {\(2\)};
    \node [fill=c1] (22) at (5,-8) {\(3\)};
    \node [fill=c3] (23) at (7,-8) {\(\)};
    \draw (1) edge (2) edge (3);
    \draw (2) edge (4) edge (5);
    \draw (3) edge (6) edge (7);
    \draw (4) edge (8) edge (9);
    \draw (5) edge (10) edge (11);
    \draw (6) edge (12) edge (13);
    \draw (7) edge (14) edge (15);
    \draw (8) edge (16);
    \draw (9) edge (17);
    \draw (10) edge (18);
    \draw (11) edge (19);
    \draw (12) edge (20);
    \draw (13) edge (21);
    \draw (14) edge (22);
    \draw (15) edge (23);
  \end{tikzpicture}
  \caption{Finding maximal cliques exhaustive tree example.}
  \label{fig:maxexall}
\end{figure}

Exponential algorithms can walk their state trees in either depth-first or breadth-first fashion Breadth-first
walks require that entire levels be maintained in memory, whereas depth-first walks only require that the current
branch be maintained in memory.  Since state trees are generally much wider than they are deep, depth-first walks
are almost always more desirable.

When the state tree is binary and balanced like this example, it is easy to calculate that the number of required
steps (branches) is \(2^{n+1}-2\).  Thus, there are \(14\) required steps to generate all of the subgraphs for this
example.  But that is not the entire story.  Once all of the subgraphs have been generated, each one needs to be
evaluated to see if it is a maximal clique.  This requires an extra \(11\) steps as follows:
\begin{enumerate}
\item Eliminate \(123\) due to nonadjacent nodes.
\item Verify that \(12\) has all adjacent nodes.
\item Eliminate \(13\) due to nonadjacent nodes.
\item Verify that \(1\) has all adjacent nodes.
\item Eliminate \(1\) as a subset of \(12\).
\item Eliminate \(23\) due to nonadjacent nodes.
\item Verify that \(2\) has all adjacent nodes.
\item Eliminate \(2\) as a subset of \(12\).
\item Verify that \(3\) has all adjacent nodes.
\item Verify that \(3\) is not a subset of \(12\).
\item Eliminate the null graph.
\end{enumerate}

In fact, each of the subset checks will take an addition number of steps, so the actual number of steps is greater
than the \(25\) already mentioned.

It would be better to terminate subtrees as soon as a nonadjacent vertex is added to a subset of adjacent vertices.
Such a test is called a \emph{bounding} condition and subtrees that are terminated due to bounding conditions are
said to be \emph{pruned}.  Branching algorithms that have bounding conditions are called \emph{branch and bound}
algorithms.  The goal of any branch and bound algorithm is to prune as many subtrees as possible using bounding
conditions.  The new tree with the nonadjacent bounding condition applied is shown in
\figurename~\ref{fig:boundnonadj}.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[every node/.style={labeled node}]
    \colorlet{c1}{green!25!white}
    \colorlet{c2}{blue!25!white}
    \node (1) at (0,0) {};
    \node (2) at (-4,-2) {\(1\)};
    \node (3) at (4,-2) {\(\bar{1}\)};
    \node (4) at (-6,-4) {\(12\)};
    \node (5) at (-2,-4) {\(1\bar{2}\)};
    \node (6) at (2,-4) {\(\bar{1}2\)};
    \node (7) at (6,-4) {\(\bar{1}\bar{2}\)};
    \node (9) at (-5,-6) {\(12\bar{3}\)};
    \node (11) at (-1,-6) {\(1\bar{2}\bar{3}\)};
    \node (13) at (3,-6) {\(\bar{1}2\bar{3}\)};
    \node (14) at (5,-6) {\(\bar{1}\bar{2}3\)};
    \node [fill=c1] (17) at (-5,-8) {\(12\)};
    \node [fill=c2] (19) at (-1,-8) {\(1\)};
    \node [fill=c2] (21) at (3,-8) {\(2\)};
    \node [fill=c1] (22) at (5,-8) {\(3\)};
    \draw (1) edge (2) edge (3);
    \draw (2) edge (4) edge (5);
    \draw (3) edge (6) edge (7);
    \draw (4) edge (9);
    \draw (5) edge (11);
    \draw (6) edge (13);
    \draw (7) edge (14);
    \draw (9) edge (17);
    \draw (11) edge (19);
    \draw (13) edge (21);
    \draw (14) edge (22);
  \end{tikzpicture}
  \caption{Finding maximal cliques nonadjacent bound.}
  \label{fig:boundnonadj}
\end{figure}

Note that any subtree that attempts to combine vertex \(3\) with either vertex \(1\) or vertex \(2\) is pruned.

There is still the problem of eliminating non-maximal cliques.  This can be accomplished by maintaining a list of
``used'' vertices for each branch edge.  When transitioning to the right from an ``include vertex'' branch to an
``exclude vertex'' branch, the excluded vertex is added to the branch's used list.  When transitioning down an
``include vertex'' branch, used vertices that are not adjacent to the newly included vertex are removed from the
branch's used list.  Thus, a leaf node resulting from a branch with a non-empty used list is a subset of some
previously found clique and thus is not maximal.  The new tree with the non-maximal bounding condition applied is
shown in \figurename~\ref{fig:boundnonmax}.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \colorlet{c1}{green!25!white}
    \colorlet{c2}{blue!25!white}
    \begin{scope}[every node/.style={labeled node}]
      \node (1) at (0,0) {};
      \node (2) at (-4,-2) {\(1\)};
      \node (3) at (4,-2) {\(\bar{1}\)};
      \node (4) at (-6,-4) {\(12\)};
      \node (5) at (-2,-4) {\(1\bar{2}\)};
      \node (6) at (2,-4) {\(\bar{1}2\)};
      \node (7) at (6,-4) {\(\bar{1}\bar{2}\)};
      \node (9) at (-5,-6) {\(12\bar{3}\)};
      \node (11) at (-1,-6) {\(1\bar{2}\bar{3}\)};
      \node (13) at (3,-6) {\(\bar{1}2\bar{3}\)};
      \node (14) at (5,-6) {\(\bar{1}\bar{2}3\)};
      \node [fill=c1] (17) at (-5,-8) {\(12\)};
      \node [fill=c1] (22) at (5,-8) {\(3\)};
    \end{scope}
    \draw (1) edge (2) edge node [auto] {\color{red}\(1\)} (3);
    \draw (2) edge (4) edge node [auto] {\color{red}\(2\)} (5);
    \draw (3) edge node [auto,swap] {\color{red}\(1\)} (6) edge node [auto] {\color{red}\(12\)} (7);
    \draw (4) edge (9);
    \draw (5) edge node [auto] {\color{red}\(2\)} (11);
    \draw (6) edge node [auto,swap] {\color{red}\(1\)} (13);
    \draw (7) edge (14);
    \draw (9) edge (17);
    \draw (14) edge (22);
  \end{tikzpicture}
  \caption{Finding maximal cliques non-maximal bound.}
  \label{fig:boundnonmax}
\end{figure}

Note that leaf node \(1\bar{2}\bar{3}\) is not maximal because vertex \(2\) remains on the used list.  Also note
that the branch from \(\bar{1}\bar{2}\) to \(\bar{1}\bar{2}3\) eliminates vertices \(1\) and \(2\) from the used
list because they are not adjacent to vertex \(3\).  Thus, \(\bar{1}\bar{2}3\) is a desired maximal clique.

Since bounding conditions are often very dependent on graph structure, it can be very hard to determine the
theoretical runtime complexity for a specific branch and bound algorithm.  This is especially true when multiple
bounding conditions interact such that it is unclear what constitutes a worst case for the algorithm.  In these
cases, runtime complexity values gleaned from empirical data (such as random graph analysis) are convenient
substitutes for truly theoretical answers.
